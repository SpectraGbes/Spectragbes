{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCpw5MJEneLVBZCw0KTGNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpectraGbes/Spectragbes/blob/main/Wild%20life%20Conservation%20in%20C%C3%B4te%20d'Ivoire%20Binary%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7CWlYVD9ebi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchinfo\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm.version import __version__ as tqdm__version__\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Platform:\", sys.platform)\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"---\")\n",
        "print(\"CV2 version : \", cv2.__version__)\n",
        "print(\"matplotlib version : \", matplotlib.__version__)\n",
        "print(\"numpy version : \", np.__version__)\n",
        "print(\"torch version : \", torch.__version__)\n",
        "print(\"torchinfo version : \", torchinfo.__version__)\n",
        "print(\"torchvision version : \", torchvision.__version__)\n",
        "print(\"PIL version : \", PIL.__version__)\n",
        "print(\"scikit-learn version: \", sklearn.__version__)\n",
        "print(\"tqdm version: \", tqdm__version__)"
      ],
      "metadata": {
        "id": "xFVPhlXu9gdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device.\")"
      ],
      "metadata": {
        "id": "dJpumUSE9jA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.path.join(\"data_p1\", \"data_binary\")\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "\n",
        "print(\"Data Directory:\", data_dir)\n",
        "print(\"Training Data Directory:\", train_dir)"
      ],
      "metadata": {
        "id": "YvG3QyJl9l1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = os.listdir(train_dir)\n",
        "labels"
      ],
      "metadata": {
        "id": "uja9HsfE9oJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hog_path = os.path.join(train_dir, \"hog\")\n",
        "hog_images = os.listdir(hog_path)\n",
        "print(\"length of hog images: \", len(hog_images))\n",
        "\n",
        "blank_path = os.path.join(train_dir, \"blank\")\n",
        "blank_images = os.listdir(blank_path)\n",
        "print(\"length of blank images: \", len(blank_images))\n"
      ],
      "metadata": {
        "id": "bfUw270K9qVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hog_image_name = hog_images[0]\n",
        "print(hog_image_name)\n",
        "\n",
        "hog_image_path = os.path.join(hog_path, hog_image_name)\n",
        "print(hog_image_path)\n",
        "\n",
        "blank_image_name = blank_images[0]\n",
        "print(blank_image_name)\n",
        "\n",
        "blank_image_path = os.path.join(blank_path, blank_image_name)\n",
        "print(blank_image_path)"
      ],
      "metadata": {
        "id": "bXdTPaxW9slq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hog_img_pil = Image.open(hog_image_path)\n",
        "print(\"Hog image: \", hog_img_pil.mode, hog_img_pil.size)\n",
        "\n",
        "blank_img_pil = Image.open(blank_image_path)\n",
        "print(\"Blank image: \", blank_img_pil.mode, blank_img_pil.size)"
      ],
      "metadata": {
        "id": "QJGeKlLm93Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blank_img_pil"
      ],
      "metadata": {
        "id": "-fxObt9496Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToRGB:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img"
      ],
      "metadata": {
        "id": "gl03lBFg98mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformation to apply to the images\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),  # Convert images to RGB format if not already\n",
        "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "        # Convert images to tensors\n",
        "        transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(type(transform))\n",
        "print(transform)"
      ],
      "metadata": {
        "id": "FI2zBaFf9_sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using `ImageFolder`\n",
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "print(dataset)\n",
        ")"
      ],
      "metadata": {
        "id": "MkOwmfSx-CNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.classes"
      ],
      "metadata": {
        "id": "18v0wdt6-E0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = dataset.imgs\n",
        "print(im[0])\n",
        "\n",
        "distinct_classes ={x[1] for x in im}\n",
        "print(distinct_classes)"
      ],
      "metadata": {
        "id": "i2QuaUpH-HKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important, don't change this!\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=g)"
      ],
      "metadata": {
        "id": "Q2b411wc-Mj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of training set: {len(train_dataset)}\")\n",
        "print(f\"Length of validation set: {len(val_dataset)}\")"
      ],
      "metadata": {
        "id": "fcQ_Wpbk-Nuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_counts(dataset):\n",
        "    c = Counter(x[1] for x in tqdm(dataset))\n",
        "    class_to_index = dataset.dataset.class_to_idx\n",
        "    return pd.Series({cat: c[idx] for cat, idx in class_to_index.items()})"
      ],
      "metadata": {
        "id": "nGn1yLAH-QKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts = class_counts(train_dataset)\n",
        "train_counts"
      ],
      "metadata": {
        "id": "Vy8ZE-wO-SKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts.sort_values().plot(kind=\"bar\");"
      ],
      "metadata": {
        "id": "E2ehRj7S-U5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_counts = class_counts(val_dataset)\n",
        "# Make a bar chart from the function output\n",
        "val_counts.sort_values().plot(kind=\"bar\")"
      ],
      "metadata": {
        "id": "TYkbn7Y2-XhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important, don't change this!\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(type(val_loader))"
      ],
      "metadata": {
        "id": "w3BxdHK0-acS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# This gives you [batch_size, channels, height, width] for images\n",
        "image_shape = images.shape\n",
        "print(\"Shape of batch of images\", image_shape)\n",
        "\n",
        "# This gives you [batch_size] for labels\n",
        "label_shape = labels.shape\n",
        "print(\"Shape of batch of labels:\", label_shape)"
      ],
      "metadata": {
        "id": "wywJdOSu-c-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "vvbrL0LD-fI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "tensor_flatten = flatten(images)\n",
        "\n",
        "# Print the shape of the flattened tensor\n",
        "print(f\"Shape of flattened tensor: {tensor_flatten.shape}\")"
      ],
      "metadata": {
        "id": "jgRMCtXqBMNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size from our transformer\n",
        "height = 224\n",
        "width = 224\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3 * height * width, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 128),\n",
        "    nn.ReLU(),\n",
        ")\n",
        "\n",
        "print(\"model type:\", type(model))\n",
        "print(\"model structure:\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "BC8pmPqyBOra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = nn.Linear(128, 2)\n",
        "model.append(output_layer)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "OCKtsZj2BQFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Z1q0V-JvBT-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "lsC3cj2WBWt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "3KGcJORYBZMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "uEzeCMF7BbMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, loss_fn, data_loader, device=\"cpu\"):\n",
        "    # We'll report the loss function's average value at the end of the epoch.\n",
        "    training_loss = 0.0\n",
        "\n",
        "    # The train method simply sets the model in training mode. No training\n",
        "    # has happened.\n",
        "    model.train()\n",
        "\n",
        "    # We iterate over all batches in the training set to complete one epoch\n",
        "    for inputs, targets in tqdm(data_loader, desc=\"Training\", leave=False):\n",
        "        # Sets the gradients to zero. We need to do this every time.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack images (X) and labels (y) from the batch and add those\n",
        "        # tensors to the specified device.\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # We make a forward pass through the network and obtain the logits.\n",
        "        # With the logits, we can calculate our loss.\n",
        "        output = model(inputs)\n",
        "        loss = loss_fn(output, targets)\n",
        "\n",
        "        # After calculating our loss, we calculate the numerical value of\n",
        "        # the derivative of our loss function with respect to all the\n",
        "        # trainable model weights. Once we have the gradients calculated,\n",
        "        # we let the optimizer take a \"step\", in other words, update or\n",
        "        # adjust the model weights.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # We increment the training loss for the current batch\n",
        "        training_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "    # We calculate the training loss over the completed epoch\n",
        "    return training_loss / len(data_loader.dataset)"
      ],
      "metadata": {
        "id": "pSVfD3KjBe0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_value = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
        "print(f\"The average loss during the training epoch was {loss_value:.2f}.\")"
      ],
      "metadata": {
        "id": "NiXL0IU2BhyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_value = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
        "print(f\"The average loss during the training epoch was {loss_value:.2f}.\")"
      ],
      "metadata": {
        "id": "DotqeEA0BkeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data_loader, device=\"cpu\"):\n",
        "    # This tensor will store all of the predictions.\n",
        "    all_probs = torch.tensor([]).to(device)\n",
        "\n",
        "    # We set the model to evaluation mode. This mode is the opposite of\n",
        "    # train mode we set in the train_epoch function.\n",
        "    model.eval()\n",
        "\n",
        "    # Since we're not training, we don't need any gradient calculations.\n",
        "    # This tells PyTorch not to calculate any gradients, which speeds up\n",
        "    # some calculations.\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Again, we iterate over the batches in the data loader and feed\n",
        "        # them into the model for the forward pass.\n",
        "        for inputs, targets in tqdm(data_loader, desc=\"Predicting\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "\n",
        "            # The model produces the logits.  This softmax function turns the\n",
        "            # logits into probabilities.  These probabilities are concatenated\n",
        "            # into the `all_probs` tensor.\n",
        "            probs = F.softmax(output, dim=1)\n",
        "            all_probs = torch.cat((all_probs, probs), dim=0)\n",
        "\n",
        "    return all_probs"
      ],
      "metadata": {
        "id": "Oz_6EcqVBnDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities_train = predict(model, train_loader, device)\n",
        "print(probabilities_train.shape)"
      ],
      "metadata": {
        "id": "6hKeljauBphb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader.dataset)"
      ],
      "metadata": {
        "id": "bjhk33vSBr4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities_val = predict(model, val_loader, device)\n",
        "print(probabilities_val.shape)"
      ],
      "metadata": {
        "id": "IWym4ADzBt_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(probabilities_train[0])"
      ],
      "metadata": {
        "id": "_tedQEJRBwqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities_train[0].sum()"
      ],
      "metadata": {
        "id": "xQONyyIcBzHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the probabilities of the first row\n",
        "print(probabilities_val[0])"
      ],
      "metadata": {
        "id": "Mc-Xqzw1B1J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_probability = probabilities_val[0].sum()\n",
        "print(f\"Sum of probabilities: {total_probability.item()}\")"
      ],
      "metadata": {
        "id": "8SWOcFcgB3nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_train = torch.argmax(probabilities_train, dim=1)\n",
        "\n",
        "print(f\"Predictions shape: {predictions_train.shape}\")\n",
        "print(f\"First 10 predictions: {predictions_train[:10]}\")"
      ],
      "metadata": {
        "id": "s3WqKKofB5_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_val = torch.argmax(probabilities_val, dim=1)\n",
        "\n",
        "print(f\"Predictions shape: {predictions_val.shape}\")\n",
        "print(f\"First 10 predictions: {predictions_val[:10]}\")"
      ],
      "metadata": {
        "id": "lj6Ky2siB8Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_train = torch.cat([labels for _, labels in train_loader]).to(device)\n",
        "is_correct_train = torch.eq(predictions_train, targets_train)\n",
        "total_correct_train = torch.sum(is_correct_train).item()\n",
        "accuracy_train = total_correct_train / len(train_loader.dataset)\n",
        "\n",
        "print(f\"Accuracy on the training data: {accuracy_train}\")"
      ],
      "metadata": {
        "id": "Ts43GmkIB-mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_val = torch.cat([labels for _, labels in val_loader]).to(device)\n",
        "is_correct_val = torch.eq(predictions_val, targets_val)\n",
        "total_correct_val = torch.sum(is_correct_val).item()\n",
        "accuracy_val = total_correct_val / len(val_loader.dataset)\n",
        "\n",
        "print(f\"Accuracy on the validation data: {accuracy_val}\")"
      ],
      "metadata": {
        "id": "Tq8UqVpGCBLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(model, data_loader, loss_fn, device=\"cpu\"):\n",
        "    # Initialize the total loss (cross entropy) and the number of correct\n",
        "    # predictions. We'll increment these values as we loop through the\n",
        "    # data.\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    # We set the model to evaluation mode. This mode is the opposite of\n",
        "    # train mode we set in the train_epoch function.\n",
        "    model.eval()\n",
        "\n",
        "    # Since we're not training, we don't need any gradient calculations.\n",
        "    # This tells PyTorch not to calculate any gradients, which speeds up\n",
        "    # some calculations.\n",
        "    with torch.no_grad():\n",
        "        # We iterate over the batches in the data loader and feed\n",
        "        # them into the model for the forward pass.\n",
        "        for inputs, targets in tqdm(data_loader, desc=\"Scoring\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "\n",
        "            # Calculating the loss function for this batch\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets)\n",
        "            total_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "            # Calculating the correct predictions for this batch\n",
        "            correct = torch.eq(torch.argmax(output, dim=1), targets)\n",
        "            total_correct += torch.sum(correct).item()\n",
        "\n",
        "    return total_loss / len(data_loader.dataset), total_correct / len(\n",
        "        data_loader.dataset\n",
        "    )"
      ],
      "metadata": {
        "id": "wCAlJI7_CEUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train, accuracy_train = score(model, train_loader, loss_fn, device)\n",
        "print(f\"Training accuracy from score function: {accuracy_train}\")"
      ],
      "metadata": {
        "id": "ujC-nQqxCGus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val, accuracy_val = score(model, val_loader, loss_fn, device)\n",
        "print(f\"Validation accuracy from score function: {accuracy_val}\")"
      ],
      "metadata": {
        "id": "jEFOjbeGCJcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Run train_epoch once, and capture the training loss.\n",
        "        training_loss = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
        "\n",
        "        # Score the model on the validation data.\n",
        "        validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch}, Training Loss: {training_loss:.2f}, \"\n",
        "            f\"Validation Loss: {validation_loss:.2f}, Validation Accuracy: {validation_accuracy:.2f}\"\n",
        "        )"
      ],
      "metadata": {
        "id": "dg7LaMe6CNa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=device)"
      ],
      "metadata": {
        "id": "yA8DMd2VCQAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, loss_fn, train_loader, val_loader, epochs=2, device=device)"
      ],
      "metadata": {
        "id": "wa5A9mtHCTrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"model/trained_model.pth\", weights_only=False)"
      ],
      "metadata": {
        "id": "fJcrvgDpCWX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(targets_val.cpu(), predictions_val.cpu())\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"blank\", \"hog\"])\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\");"
      ],
      "metadata": {
        "id": "9vMkG1ZjCZET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = os.path.join(data_dir, \"train/hog/ZJ000072.jpg\")"
      ],
      "metadata": {
        "id": "fTFKl_8MCbgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"blank\", \"hog\"]\n",
        "\n",
        "img = Image.open(os.path.join(data_dir, \"train/hog/ZJ000072.jpg\"))\n",
        "img = transform(img).to(device)\n",
        "img = torch.unsqueeze(img, 0)\n",
        "\n",
        "model.eval()\n",
        "prediction = F.softmax(model(img), dim=1)\n",
        "prediction = prediction.argmax()\n",
        "print(labels[prediction])"
      ],
      "metadata": {
        "id": "1ebI4lySCeBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(model(img), dim=1)"
      ],
      "metadata": {
        "id": "Z3ZGwSgLCg-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, os.path.join(\"model\", \"shallownet\"))\n",
        "model = torch.load(os.path.join(\"model\", \"shallownet\"))"
      ],
      "metadata": {
        "id": "7bu6564uCjLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), os.path.join(\"model\", \"shallownet\"))\n",
        "new_model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3 * height * width, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 2),\n",
        ")\n",
        "model_state_dict = torch.load(os.path.join(\"model\", \"shallownet\"))\n",
        "new_model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "bs3_jZ0GCmDb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}