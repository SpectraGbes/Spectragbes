{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1Du535RIrW0X0FqP+z9RK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpectraGbes/Spectragbes/blob/main/Wild%20life%20Conservation%20in%20C%C3%B4te%20d'Ivoire%20(Multiclass).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sISbYvoMkhQp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Platform:\", sys.platform)\n",
        "print(\"Python version:\", sys.version)\n",
        "print(\"---\")\n",
        "print(\"matplotlib version:\", matplotlib.__version__)\n",
        "print(\"pandas version:\", pd.__version__)\n",
        "print(\"PIL version:\", PIL.__version__)\n",
        "print(\"torch version:\", torch.__version__)\n",
        "print(\"torchvision version:\", torchvision.__version__)"
      ],
      "metadata": {
        "id": "bjb6zMb9klKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device.\")"
      ],
      "metadata": {
        "id": "bQljRpW8kpFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToRGB:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img"
      ],
      "metadata": {
        "id": "vxbuqBEvkrnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "U6o9YIM5ksVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"data_p1/data_multiclass/\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "\n",
        "print(\"Will read data from\", train_dir)"
      ],
      "metadata": {
        "id": "UGVPzw0TkwWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ],
      "metadata": {
        "id": "ZyUalWVfkytx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classes:\")\n",
        "print(dataset.classes)\n",
        "print(f\"That's {len(dataset.classes)} classes\")\n",
        "print()\n",
        "print(\"Tensor shape for one image:\")\n",
        "print(dataset[0][0].shape)"
      ],
      "metadata": {
        "id": "5V9sCQc-k07A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "# Get one batch\n",
        "first_batch = next(iter(dataset_loader))\n",
        "\n",
        "print(f\"Shape of one batch: {first_batch[0].shape}\")\n",
        "print(f\"Shape of labels: {first_batch[1].shape}\")"
      ],
      "metadata": {
        "id": "ZX16htYWk3Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_std(loader):\n",
        "    \"\"\"Computes the mean and standard deviation of image data.\n",
        "\n",
        "    Input: a `DataLoader` producing tensors of shape [batch_size, channels, pixels_x, pixels_y]\n",
        "    Output: the mean of each channel as a tensor, the standard deviation of each channel as a tensor\n",
        "            formatted as a tuple (means[channels], std[channels])\"\"\"\n",
        "\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in tqdm(loader, desc=\"Computing mean and std\", leave=False):\n",
        "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "        num_batches += 1\n",
        "    mean = channels_sum / num_batches\n",
        "    std = (channels_squared_sum / num_batches - mean**2) ** 0.5\n",
        "\n",
        "    return mean, std"
      ],
      "metadata": {
        "id": "6axaS7tok7kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, std = get_mean_std(dataset_loader)\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")"
      ],
      "metadata": {
        "id": "JMpFZkuZk8zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_norm = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "4RqEklvjlAQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_mean, norm_std = get_mean_std(norm_loader)\n",
        "\n",
        "print(f\"Mean: {norm_mean}\")\n",
        "print(f\"Standard deviation: {norm_std}\")"
      ],
      "metadata": {
        "id": "lZvlOWiNlBZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1 / 3 - 1 / 5 - 2 / 15"
      ],
      "metadata": {
        "id": "meAS805HlDc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important, don't change this!\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "train_dataset, val_dataset = random_split(norm_dataset, [0.8, 0.2])\n",
        "\n",
        "length_train = len(train_dataset)\n",
        "length_val = len(val_dataset)\n",
        "length_dataset = len(norm_dataset)\n",
        "percent_train = np.round(100 * length_train / length_dataset, 2)\n",
        "percent_val = np.round(100 * length_val / length_dataset, 2)\n",
        "\n",
        "print(f\"Train data is {percent_train}% of full data\")\n",
        "print(f\"Validation data is {percent_val}% of full data\")"
      ],
      "metadata": {
        "id": "qk88JJRqlFiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_counts(dataset):\n",
        "    c = Counter(x[1] for x in tqdm(dataset))\n",
        "    class_to_index = dataset.dataset.class_to_idx\n",
        "    return pd.Series({cat: c[idx] for cat, idx in class_to_index.items()})"
      ],
      "metadata": {
        "id": "4UNcI3yrlIaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_class_distributions = class_counts(train_dataset)\n",
        "\n",
        "train_class_distributions"
      ],
      "metadata": {
        "id": "-dnad8dLlNHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot from train_class_distribution\n",
        "train_class_distributions.sort_values().plot(kind='bar')\n",
        "\n",
        "# Add axis labels and title\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Frequency [count]\")\n",
        "plt.title(\"Class Distribution in Training Set\");"
      ],
      "metadata": {
        "id": "rdlTYjVflOCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class distribution\n",
        "validation_class_distributions = class_counts(val_dataset)\n",
        "\n",
        "# Create a bar plot from train_class_distribution\n",
        "validation_class_distributions.sort_values().plot(kind='bar')\n",
        "\n",
        "# Add axis labels and title\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Frequency [count]\")\n",
        "plt.title(\"Class Distribution in Validation Set\");"
      ],
      "metadata": {
        "id": "Lb2cuRvJlUhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important, don't change this!\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "single_batch = next(iter(train_loader))[0]\n",
        "print(f\"Shape of one batch: {single_batch.shape}\")"
      ],
      "metadata": {
        "id": "8RY4VoShlXXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_confidence = torch.tensor([0.13, 0.01, 0.02, 0.12, 0.10, 0.34, 0.16, 0.12])"
      ],
      "metadata": {
        "id": "o_9cvFO7lYfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = norm_dataset.classes\n",
        "\n",
        "class_number = torch.argmax(sample_confidence)\n",
        "prediction = classes[class_number]\n",
        "\n",
        "print(f\"This image is a {prediction}\")"
      ],
      "metadata": {
        "id": "7fKbwKDJleMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq = torch.nn.Sequential()"
      ],
      "metadata": {
        "id": "sxfGB_-IlgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1)\n",
        "model_seq.append(conv1)"
      ],
      "metadata": {
        "id": "b6mW0Qw5liLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = next(iter(train_loader))[0]"
      ],
      "metadata": {
        "id": "pQew0wghlk5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T_DRvZRQlnMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_shape = test_batch.shape\n",
        "\n",
        "print(f\"Batch shape: {batch_shape}\")"
      ],
      "metadata": {
        "id": "sxXRXG7HlqCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_step_out = model_seq(test_batch)"
      ],
      "metadata": {
        "id": "3sSIFwQ2lsmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_step_shape = first_step_out.shape"
      ],
      "metadata": {
        "id": "v0YGUyHVlvl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.append(torch.nn.ReLU())"
      ],
      "metadata": {
        "id": "0Ef-k_TLlz5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool1 = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "model_seq.append(max_pool1)"
      ],
      "metadata": {
        "id": "ZVJbDQR5l1eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool_out = model_seq(test_batch)\n",
        "max_pool_shape = max_pool_out.shape\n",
        "\n",
        "print(f\"Shape after first max pool: {max_pool_shape}\")"
      ],
      "metadata": {
        "id": "NWTvyIInl8ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_conv = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "second_pool = torch.nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "model_seq.append(second_conv)\n",
        "model_seq.append(torch.nn.ReLU())\n",
        "model_seq.append(second_pool)\n"
      ],
      "metadata": {
        "id": "1bTRyCDdmBIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_set_out = model_seq(test_batch)\n",
        "second_set_shape = second_set_out.shape\n",
        "\n",
        "print(f\"Shape after second max pool: {second_set_shape}\")"
      ],
      "metadata": {
        "id": "DGmNu3YJmE1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
        "max_pool3 = torch.nn.MaxPool2d(2)\n",
        "model_seq.append(conv3)\n",
        "model_seq.append(torch.nn.ReLU())\n",
        "model_seq.append(max_pool3)"
      ],
      "metadata": {
        "id": "QollgvwwmFty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_set_out = model_seq(test_batch)\n",
        "third_set_shape = third_set_out.shape\n",
        "\n",
        "print(f\"Shape after third max pool: {third_set_shape}\")"
      ],
      "metadata": {
        "id": "_cqiq4_jmKnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.append(torch.nn.Flatten())"
      ],
      "metadata": {
        "id": "VKWTmsi9mNC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "64 * 28 * 28"
      ],
      "metadata": {
        "id": "I1JB3lHxmO55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_out = model_seq(test_batch)\n",
        "flat_shape = flat_out.shape\n",
        "\n",
        "print(f\"Shape after flattening: {flat_shape}\")"
      ],
      "metadata": {
        "id": "hfgPdES6mQuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear1 = torch.nn.Linear(in_features=50176, out_features=500)\n",
        "\n",
        "model_seq.append(linear1)"
      ],
      "metadata": {
        "id": "D7okRPknmSqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.append(torch.nn.ReLU())"
      ],
      "metadata": {
        "id": "g3hBslJomWIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_out = model_seq(test_batch)\n",
        "linear_shape = linear_out.shape\n",
        "\n",
        "print(f\"Shape after linear layer: {linear_shape}\")"
      ],
      "metadata": {
        "id": "Ntv0CLMNmXAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = torch.nn.Linear(in_features=500, out_features=8, bias=True)\n",
        "\n",
        "model_seq.append(output_layer)"
      ],
      "metadata": {
        "id": "UN64EaNWmY16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "model = torch.nn.Sequential()\n",
        "\n",
        "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1)\n",
        "max_pool1 = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "model.append(conv1)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool1)\n",
        "\n",
        "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1)\n",
        "max_pool2 = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "model.append(conv2)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool2)\n",
        "\n",
        "conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
        "max_pool3 = torch.nn.MaxPool2d(2)\n",
        "model.append(conv3)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(max_pool3)\n",
        "\n",
        "model.append(torch.nn.Flatten())\n",
        "model.append(torch.nn.Dropout())\n",
        "\n",
        "linear1 = torch.nn.Linear(in_features=50176, out_features=500)\n",
        "model.append(linear1)\n",
        "model.append(torch.nn.ReLU())\n",
        "model.append(torch.nn.Dropout())\n",
        "\n",
        "output_layer = torch.nn.Linear(500, 8)\n",
        "model.append(output_layer)"
      ],
      "metadata": {
        "id": "YpZhbaaxmiH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = 224, 224\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "1BUFuqTFmnay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "X0IqLhWXmuDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"model/trained_model.pth\", weights_only=False)"
      ],
      "metadata": {
        "id": "0TP_cIPfmwjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "\n",
        "for _, labels in tqdm(val_loader):\n",
        "    targets.extend(labels.tolist())"
      ],
      "metadata": {
        "id": "3vJLH5xOm3u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(targets, predictions.cpu())\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "6urngujNm6h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file\n",
        "id_file_location = os.path.join(test_dir, 'test_features.csv')\n",
        "df_ids = pd.read_csv(id_file_location)\n",
        "\n",
        "df_ids.head()"
      ],
      "metadata": {
        "id": "63eeuflfnEIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_location = df_ids.iloc[0, 1]\n",
        "test_image_location"
      ],
      "metadata": {
        "id": "kbUG-TndnGe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = os.path.join(test_dir, test_image_location)\n",
        "test_image = PIL.Image.open(test_image_path)\n",
        "test_image"
      ],
      "metadata": {
        "id": "qr6uCTv1nKVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_trans = transform_norm(test_image)\n",
        "test_image_trans.shape"
      ],
      "metadata": {
        "id": "Hwd5DwmnnOaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unsqueeze = test_image_trans.unsqueeze(0)\n",
        "test_unsqueeze.shape"
      ],
      "metadata": {
        "id": "jDTK1dBAnQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_cuda = test_unsqueeze.to(device)\n",
        "test_out = model(test_image_cuda)\n",
        "test_out"
      ],
      "metadata": {
        "id": "ivVn81vZnRx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_softmax = torch.nn.functional.softmax(test_out, dim=1)\n",
        "test_softmax"
      ],
      "metadata": {
        "id": "dxIEF0x6nT4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(test_softmax.tolist())\n",
        "test_df.columns = dataset.classes\n",
        "\n",
        "test_df"
      ],
      "metadata": {
        "id": "hJskpRmLnZWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_id = df_ids.iloc[0, 0]\n",
        "test_df.index = [image_id]\n",
        "\n",
        "test_df"
      ],
      "metadata": {
        "id": "gYW_Uxtanb2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "\n",
        "def file_to_confidence(file_path, image_id):\n",
        "    image = PIL.Image.open(file_path)\n",
        "    transformed = transform_norm(image)\n",
        "    unsqueezed = transformed.unsqueeze(0)\n",
        "    image_cuda = unsqueezed.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model_raw = model(image_cuda)\n",
        "        confidence = torch.nn.functional.softmax(model_raw, dim=1)\n",
        "\n",
        "    conf_df = pd.DataFrame(confidence.tolist())\n",
        "    conf_df.columns = dataset.classes\n",
        "    conf_df.index = [image_id]\n",
        "\n",
        "    return conf_df"
      ],
      "metadata": {
        "id": "_2chYGdFngyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_to_confidence(test_image_path, image_id)"
      ],
      "metadata": {
        "id": "c1Kr0zCnnlfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_dfs = []\n",
        "\n",
        "for row in df_ids.itertuples():\n",
        "    image_id = row.id\n",
        "    file_loc = row.filepath\n",
        "    filepath = os.path.join(test_dir, file_loc)\n",
        "    small_dfs.append(file_to_confidence(filepath, image_id))\n",
        "\n",
        "confidence_df = pd.concat(small_dfs)"
      ],
      "metadata": {
        "id": "xhCD6OrUnoti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_df.to_csv(\"submission.csv\")"
      ],
      "metadata": {
        "id": "WpEZlvnHnq7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"model/deepnet\")"
      ],
      "metadata": {
        "id": "iOPHU65pnu67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}