{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPafDQ+9cAvwbrwrOFdhglV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpectraGbes/Spectragbes/blob/main/Crop%20Disease%20in%20Uganda%20Explore%20Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkNlc_iADtho"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from shutil import copy2\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch version : \", torch.__version__)\n",
        "print(\"torchvision version : \", torchvision.__version__)\n",
        "print(\"numpy version : \", np.__version__)\n",
        "print(\"matplotlib version : \", matplotlib.__version__)\n",
        "\n",
        "!python --version"
      ],
      "metadata": {
        "id": "lVzdlL9mDwMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l data_p2"
      ],
      "metadata": {
        "id": "T76pcGtHD0hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"data_p2\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "\n",
        "print(\"Data directory:\", train_dir)"
      ],
      "metadata": {
        "id": "2iAPkVcpD2hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = os.listdir(train_dir)\n",
        "classes"
      ],
      "metadata": {
        "id": "AB-5FRBCD4n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(data_path, classname):\n",
        "    # Gets the files in the directory\n",
        "    class_dir = os.path.join(data_path, classname)\n",
        "    if not os.path.exists(class_dir):\n",
        "        return \"Invalid directory\"\n",
        "    image_list = os.listdir(class_dir)\n",
        "    if len(image_list) < 4:\n",
        "        return \"Not enough images in folder\"\n",
        "\n",
        "    # Pick four random images\n",
        "    images_sample = random.sample(image_list, 4)\n",
        "\n",
        "    # Plot them\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(4):\n",
        "        img_loc = os.path.join(class_dir, images_sample[i])\n",
        "        img = PIL.Image.open(img_loc)\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "s0zyiGV_D7Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images(train_dir, \"cassava-healthy\")"
      ],
      "metadata": {
        "id": "6WyGoCrOD-EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "id": "rNzhQp7CD_0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToRGB(object):\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img"
      ],
      "metadata": {
        "id": "WglN76cwEE7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_basic = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "1A5u1i12EI10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform_basic)\n",
        "dataset_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "batch_shape = next(iter(dataset_loader))[0].shape\n",
        "print(\"Getting batches of shape:\", batch_shape)"
      ],
      "metadata": {
        "id": "VI-YW5WoEL_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_std(loader):\n",
        "    \"\"\"Computes the mean and standard deviation of image data.\n",
        "\n",
        "    Input: a `DataLoader` producing tensors of shape [batch_size, channels, pixels_x, pixels_y]\n",
        "    Output: the mean of each channel as a tensor, the standard deviation of each channel as a tensor\n",
        "            formatted as a tuple (means[channels], std[channels])\"\"\"\n",
        "\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in tqdm(loader, desc=\"Computing mean and std\", leave=False):\n",
        "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "        num_batches += 1\n",
        "    mean = channels_sum / num_batches\n",
        "    std = (channels_squared_sum / num_batches - mean**2) ** 0.5\n",
        "\n",
        "    return mean, std"
      ],
      "metadata": {
        "id": "WLkug0fUEOdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, std = get_mean_std(dataset_loader)\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")"
      ],
      "metadata": {
        "id": "ESgPgmNsERkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_norm = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "zHJyRuXaETuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dataset = datasets.ImageFolder(root=train_dir, transform=transform_norm)\n",
        "norm_loader = DataLoader(dataset=norm_dataset, batch_size=32)\n",
        "\n",
        "batch_shape = next(iter(norm_loader))[0].shape\n",
        "print(\"Getting batches of shape:\", batch_shape)"
      ],
      "metadata": {
        "id": "coP6v016EWqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_mean, norm_std = get_mean_std(norm_loader)\n",
        "\n",
        "print(f\"Mean: {norm_mean}\")\n",
        "print(f\"Standard deviation: {norm_std}\")"
      ],
      "metadata": {
        "id": "PhuNvuFJEY3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = random_split(norm_dataset, [0.8, 0.2])\n",
        "\n",
        "length_train = len(train_dataset)\n",
        "length_val = len(val_dataset)\n",
        "length_dataset = len(norm_dataset)\n",
        "percent_train = np.round(100 * length_train / length_dataset, 2)\n",
        "percent_val = np.round(100 * length_val / length_dataset, 2)\n",
        "\n",
        "print(f\"Train data is {percent_train}% of full data\")\n",
        "print(f\"Validation data is {percent_val}% of full data\")"
      ],
      "metadata": {
        "id": "7e-VPxRSEbPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from training import class_counts"
      ],
      "metadata": {
        "id": "uOpnTjXLEj18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts = class_counts(train_dataset)\n",
        "train_counts"
      ],
      "metadata": {
        "id": "s90f1_1WEltk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts.plot(kind=\"bar\");"
      ],
      "metadata": {
        "id": "Vr7crf6MEoGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_counts = class_counts(val_dataset)\n",
        "val_counts"
      ],
      "metadata": {
        "id": "xY4KJXxsEq80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart from val_counts\n",
        "val_counts.plot(kind=\"bar\");"
      ],
      "metadata": {
        "id": "m0iV4HZiEtH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def undersample_dataset(dataset_dir, output_dir, target_count=None):\n",
        "    \"\"\"\n",
        "    Undersample the dataset to have a uniform distribution across classes.\n",
        "\n",
        "    Parameters:\n",
        "    - dataset_dir: Path to the directory containing the class folders.\n",
        "    - output_dir: Path to the directory where the undersampled dataset will be stored.\n",
        "    - target_count: Number of instances to keep in each class. If None, the class with the least instances will set the target.\n",
        "    \"\"\"\n",
        "    # Mapping each class to its files\n",
        "    classes_files = {}\n",
        "    for class_name in os.listdir(dataset_dir):\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            files = os.listdir(class_dir)\n",
        "            classes_files[class_name] = files\n",
        "\n",
        "    # Determine the minimum class size if target_count is not set\n",
        "    if target_count is None:\n",
        "        target_count = min(len(files) for files in classes_files.values())\n",
        "\n",
        "    # Creating the output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Perform undersampling\n",
        "    for class_name, files in classes_files.items():\n",
        "        print(\"Copying images for class\", class_name)\n",
        "        class_output_dir = os.path.join(output_dir, class_name)\n",
        "        if not os.path.exists(class_output_dir):\n",
        "            os.makedirs(class_output_dir)\n",
        "\n",
        "        # Randomly select target_count images\n",
        "        selected_files = random.sample(files, min(len(files), target_count))\n",
        "\n",
        "        # Copy selected files to the output directory\n",
        "        for file_name in tqdm(selected_files):\n",
        "            src_path = os.path.join(dataset_dir, class_name, file_name)\n",
        "            dst_path = os.path.join(class_output_dir, file_name)\n",
        "            copy2(src_path, dst_path)"
      ],
      "metadata": {
        "id": "q4idIAwcEvE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = 'data_p2/data_undersampled/train'\n",
        "print(\"Output directory:\", output_dir)"
      ],
      "metadata": {
        "id": "b7zk3Y8qEyqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf {output_dir}"
      ],
      "metadata": {
        "id": "fOD475bbE1K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "undersample_dataset(train_dir, output_dir)"
      ],
      "metadata": {
        "id": "FpVWJvveE29E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "undersampled_dataset = datasets.ImageFolder(root=output_dir, transform=transform_norm)"
      ],
      "metadata": {
        "id": "51I--EYpE5KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "undersampled_dataset.classes"
      ],
      "metadata": {
        "id": "ITW9d6WxE7yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important, don't change this\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "under_counts = class_counts(undersampled_dataset)\n",
        "\n",
        "# Create a bar chart from under_counts\n",
        "# important, you must leave `ax=ax`\n",
        "under_counts.plot(kind='bar', ax=ax)"
      ],
      "metadata": {
        "id": "K4LfUXePE_20"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}