{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqA5uf6BjIrhhy9KTx8JYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpectraGbes/Spectragbes/blob/main/BCSTCAO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "CAJHAIqbc9Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\""
      ],
      "metadata": {
        "id": "lPL-WFxsdEYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"sea_creatures\")"
      ],
      "metadata": {
        "id": "p2IwrtvtdLoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToRGB:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "C3DOTtTbdUMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"sea_creatures\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "classes = datasets.ImageFolder(root=train_dir, transform=transform).classes\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "2Y0zz_lgdW8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height = 224\n",
        "width = 224\n",
        "\n",
        "\n",
        "class ConvertToRGB:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    ConvertToRGB(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "print(transform)"
      ],
      "metadata": {
        "id": "Gjxcv5YSdZlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file = \"sea_creatures/train/Dolphin/10004986625_0f786ab86b_b.jpg\"\n",
        "\n",
        "image = Image.open(sample_file)\n",
        "\n",
        "transformed_image = transform(image)\n",
        "print(transformed_image.shape)"
      ],
      "metadata": {
        "id": "jf_qdT8TdcL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "print(\"Image size\", dataset[0][0].shape)\n",
        "print(\"Label\", dataset[0][1])"
      ],
      "metadata": {
        "id": "LipHbVnQdeXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Counter(x[1] for x in tqdm(dataset))\n",
        "print(\"The counts dictionary:\", counts)\n",
        "\n",
        "\n",
        "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
        "print(\"The class_to_idx dictionary:\", dataset.class_to_idx)\n",
        "\n",
        "\n",
        "class_distribution = {idx_to_class[idx]: count for idx, count in counts.items()}\n",
        "print(class_distribution)"
      ],
      "metadata": {
        "id": "eFCtea2WdheW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "first_batch = next(iter(dataset_loader))\n",
        "\n",
        "print(f\"Shape of one batch: {first_batch[0].shape}\")\n",
        "print(f\"Shape of labels: {first_batch[1].shape}\")"
      ],
      "metadata": {
        "id": "1k88zgHUdnFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_std(loader):\n",
        "    \"\"\"Computes the mean and standard deviation of image data.\n",
        "\n",
        "    Input: a `DataLoader` producing tensors of shape [batch_size, channels, pixels_x, pixels_y]\n",
        "    Output: the mean of each channel as a tensor, the standard deviation of each channel as a tensor\n",
        "            formatted as a tuple (means[channels], std[channels])\"\"\"\n",
        "\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in tqdm(loader):\n",
        "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "        num_batches += 1\n",
        "\n",
        "    mean = channels_sum / num_batches\n",
        "\n",
        "    std = (channels_squared_sum / num_batches - mean**2) ** 0.5\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "mean, std = get_mean_std(dataset_loader)\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")"
      ],
      "metadata": {
        "id": "VROuNxW0dqQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_norm = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ]\n",
        ")\n",
        "print(transform_norm)"
      ],
      "metadata": {
        "id": "amqcEPtxdtBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dataset = datasets.ImageFolder(root=train_dir, transform=transform_norm)\n",
        "\n",
        "print(\"Image size\", norm_dataset[0][0].shape)\n",
        "print(\"Label\", norm_dataset[0][1])"
      ],
      "metadata": {
        "id": "OCtkuJDJdwH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "train_dataset, val_dataset = random_split(norm_dataset, [0.8, 0.2], generator=g)\n",
        "\n",
        "print(\"Training data set size:\", len(train_dataset))\n",
        "print(\"Validation data set size:\", len(val_dataset))"
      ],
      "metadata": {
        "id": "ubwngmIwdzAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "hNcziv8yd1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4)\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bEFgd19Fd3jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4)\n",
        ")\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "9t79F8h_d52P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4)\n",
        ")\n",
        "\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "hdk9auLAd-YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4)\n",
        ")\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "7wYdxJNDeCDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Flatten()\n",
        ")\n",
        "\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bHPAge0OeE3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Flatten()\n",
        ")\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "QTeYG8pQeH-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Flatten(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=64*3*3, out_features=500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=500, out_features=9)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "RM2E8lhdeKUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
        "    nn.Flatten(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=64*3*3, out_features=500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(in_features=500, out_features=9)\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "cmjpv9iheM_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "1dCMJGVWePfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from training import predict, train\n",
        "epochs = 10\n",
        "\n",
        "train(model, optimizer, loss_fn, train_loader, val_loader, epochs=10, device=device)"
      ],
      "metadata": {
        "id": "not-WzQpeR8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "probabilities = predict(model, val_loader, device)\n",
        "\n",
        "predictions = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "print(\"Number of predictions:\", predictions.shape)"
      ],
      "metadata": {
        "id": "AhgBHJD3eU5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "\n",
        "for _, labels in tqdm(val_loader):\n",
        "    targets.extend(labels.tolist())"
      ],
      "metadata": {
        "id": "WOaoozC_eXLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "cm = confusion_matrix(targets, predictions.cpu())\n",
        "\n",
        "\n",
        "classes = datasets.ImageFolder(root=train_dir, transform=transform).classes\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\", ax=ax)"
      ],
      "metadata": {
        "id": "F_R2N7ZzeY_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = os.path.join(data_dir, \"test\")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='sea_creatures/test', transform=transform)\n",
        "\n",
        "print(\"Number of test images:\", len(test_dataset))\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "IkyQ6wYzebxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_probabilities = predict(model, test_loader, device)\n",
        "\n",
        "test_predictions = torch.argmax(test_probabilities, dim=1)\n",
        "\n",
        "print(\"Number of predictions:\", test_predictions.shape)"
      ],
      "metadata": {
        "id": "-ciPmDEPeeBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_classes = [classes[i] for i in test_predictions]\n",
        "\n",
        "print(\"Number of class predictions:\", len(test_classes))"
      ],
      "metadata": {
        "id": "gXRk9tU5ehM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "sample_indices = random.sample(range(len(test_loader.dataset.samples)), 12)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(4, 3, figsize=(20, 10))\n",
        "\n",
        "\n",
        "for ax, idx in zip(axes.flatten(), sample_indices):\n",
        "    image_path = test_loader.dataset.samples[idx][0]\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "    predicted_class = test_classes[idx]\n",
        "\n",
        "    ax.set_title(f\"Predicted: {predicted_class}\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "C47kccTgejwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}